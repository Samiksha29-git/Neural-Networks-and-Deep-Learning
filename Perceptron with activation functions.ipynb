{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **LAB 3**"
      ],
      "metadata": {
        "id": "ooO4vP269eOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "TaExqPLw9Pzd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step(x): return np.where(x >= 0, 1, -1)\n",
        "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_deriv(x): return sigmoid(x) * (1 - sigmoid(x))\n",
        "def tanh(x): return np.tanh(x)\n",
        "def tanh_deriv(x): return 1 - np.tanh(x)**2\n",
        "def relu(x): return np.maximum(0, x)\n",
        "def relu_deriv(x): return np.where(x > 0, 1, 0)"
      ],
      "metadata": {
        "id": "R5TekZr_9Sfo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, w, b, act, threshold=True):\n",
        "    z = np.dot(x, w) + b\n",
        "    out = act(z)\n",
        "    if threshold:\n",
        "        return 1 if out >= 0.5 else 0\n",
        "    return out\n",
        "\n",
        "def train_perceptron(X, y, activation='step', lr=0.1, epochs=1000):\n",
        "    np.random.seed(0)\n",
        "    w = np.random.randn(X.shape[1]) * 0.1\n",
        "    b = 0\n",
        "\n",
        "    activations = {\n",
        "        'step': (step, None),\n",
        "        'sigmoid': (sigmoid, sigmoid_deriv),\n",
        "        'tanh': (tanh, tanh_deriv),\n",
        "        'relu': (relu, relu_deriv)\n",
        "    }\n",
        "    act, deriv = activations[activation]\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for xi, target in zip(X, y):\n",
        "            z = np.dot(xi, w) + b\n",
        "            out = act(z)\n",
        "\n",
        "            error = target - out\n",
        "            if activation == 'step':\n",
        "                w += lr * error * xi\n",
        "                b += lr * error\n",
        "            else:\n",
        "                delta = error * deriv(z)\n",
        "                w += lr * delta * xi\n",
        "                b += lr * delta\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "rfmfK5Sg9Wfg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_step = np.array([-1, -1, -1, 1])\n",
        "y_soft = np.array([0, 0, 0, 1])"
      ],
      "metadata": {
        "id": "sBdlfxbX9beM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq3Hb0h79NGi",
        "outputId": "0aa446b4-5db6-4f11-a4ce-797855894e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP activation:\n",
            "Input: [0 0], Target: -1, Prediction: 0\n",
            "Input: [0 1], Target: -1, Prediction: 0\n",
            "Input: [1 0], Target: -1, Prediction: 0\n",
            "Input: [1 1], Target: 1, Prediction: 1\n",
            "Weights: [0.17640523 0.04001572], Bias: -0.2\n",
            "\n",
            "SIGMOID activation:\n",
            "Input: [0 0], Target: 0, Prediction: 0\n",
            "Input: [0 1], Target: 0, Prediction: 0\n",
            "Input: [1 0], Target: 0, Prediction: 0\n",
            "Input: [1 1], Target: 1, Prediction: 1\n",
            "Weights: [2.63407369 2.63008563], Bias: -4.06678768823615\n",
            "\n",
            "TANH activation:\n",
            "Input: [0 0], Target: 0, Prediction: 0\n",
            "Input: [0 1], Target: 0, Prediction: 0\n",
            "Input: [1 0], Target: 0, Prediction: 0\n",
            "Input: [1 1], Target: 1, Prediction: 1\n",
            "Weights: [0.53810739 0.51364682], Bias: -0.2690536929557518\n",
            "\n",
            "RELU activation:\n",
            "Input: [0 0], Target: 0, Prediction: 0\n",
            "Input: [0 1], Target: 0, Prediction: 0\n",
            "Input: [1 0], Target: 0, Prediction: 0\n",
            "Input: [1 1], Target: 1, Prediction: 1\n",
            "Weights: [1. 1.], Bias: -0.9999999965594257\n"
          ]
        }
      ],
      "source": [
        "w_step, b_step = train_perceptron(X, y_step, activation='step')\n",
        "w_sig, b_sig = train_perceptron(X, y_soft, activation='sigmoid')\n",
        "w_tanh, b_tanh = train_perceptron(X, y_soft, activation='tanh')\n",
        "w_relu, b_relu = train_perceptron(X, y_soft, activation='relu')\n",
        "\n",
        "activations = {\n",
        "    'step': (step, True, w_step, b_step),\n",
        "    'sigmoid': (sigmoid, True, w_sig, b_sig),\n",
        "    'tanh': (tanh, True, w_tanh, b_tanh),\n",
        "    'relu': (relu, True, w_relu, b_relu)\n",
        "}\n",
        "\n",
        "print(\"\")\n",
        "for name, (act_func, threshold, w, b) in activations.items():\n",
        "    print(f\"\\n{name.upper()} activation:\")\n",
        "    for xi, target in zip(X, y_soft if name != 'step' else y_step):\n",
        "        pred = predict(xi, w, b, act_func, threshold)\n",
        "        print(f\"Input: {xi}, Target: {target}, Prediction: {pred}\")\n",
        "    print(f\"Weights: {w}, Bias: {b}\")\n"
      ]
    }
  ]
}